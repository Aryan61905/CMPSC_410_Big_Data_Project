{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4087bd0-5dd0-47f9-90e9-2f9fe30a88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nm\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, column\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import Row\n",
    "import csv\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, IndexToString, StandardScaler, PCA\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce7cd2-0e75-45f9-a876-b440dd12dde2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784e8a2-1b8f-4ac1-9235-1bba7b669a4d",
   "metadata": {},
   "source": [
    "## Initialize a SparkSession, define the csv Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9237ef82-410c-405d-8382-3b716e17a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e73d57f-5cf4-458d-b662-e02e70fac54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ StructField(\"ID\", IntegerType(), False ), \\\n",
    "                        StructField(\"Case Number\", StringType(), False), \\\n",
    "                        StructField(\"Date\", StringType(), False ), \\\n",
    "                        StructField(\"Block\", StringType(), False ), \\\n",
    "                        StructField(\"IUCR\", StringType(), False), \\\n",
    "                        StructField(\"Primary Type\", StringType(), False), \\\n",
    "                        StructField(\"Description\", StringType(), False),\\\n",
    "                        StructField(\"Location Description\", StringType(), False), \\\n",
    "                        StructField(\"Arrest\", StringType(), False), \\\n",
    "                        StructField(\"Domestic\", StringType(), False), \\\n",
    "                        StructField(\"District\", StringType(), False) ,\\\n",
    "                        StructField(\"Ward\", StringType(), False ), \\\n",
    "                        StructField(\"Community Area\", StringType(), False ), \\\n",
    "                        StructField(\"FBI Code\", StringType(), False), \\\n",
    "                        StructField(\"Year\", StringType(), False), \\\n",
    "                        StructField(\"Latitude\", StringType(), False),\\\n",
    "                        StructField(\"Longitude\", StringType(), False)\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3793f47a-7f40-4d0d-828d-1829c0fd44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_file3.csv is the file generated by using Suvarna's code\n",
    "data = ss.read.csv(\"./new_file3.csv\",schema=schema,header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d854774f-3dd5-4039-a5f7-575999474706",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Case Number').drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b10989-78ba-4f34-9bef-08a63040386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' to hours\n",
    "data = data.withColumn('Hour', pyspark.sql.functions.hour(pyspark.sql.functions.to_timestamp('Date', 'MM/dd/yyyy hh:mm:ss a')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858e103-8c54-464c-80db-a7b92cb29195",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07a9fe-c59d-432d-9087-3c763eeb3544",
   "metadata": {},
   "source": [
    "## Apply PCA Reduction (for model training only, not for visualization)\n",
    "#### Reason: I tried directly using Lab8's code before. However, I continously got an error saying the data's cardinality is too high and aborted the task, which means the dataset's size is too large. To reduce the dataset's size, I need to use PCA reduction first to reduce the size and then use the reduced data to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91439939-43e6-462d-8bab-524fab27ce0f",
   "metadata": {},
   "source": [
    "`Step 1: Transforms a column of string to a new column of index (type double)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b640875-f12d-42a5-b51d-a46d896a4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block will create a new column for each indexed column, for example, will create a 'i_date' for indexed 'Date' column\n",
    "columns_to_index = [\"Date\", \"Primary Type\", \"Description\", \"IUCR\",\"Year\",\"Block\",\n",
    "                    \"Location Description\", \"Arrest\", \"Domestic\", \"District\",\"Ward\",\"FBI Code\",\"Community Area\", \n",
    "                    \"Latitude\", \"Longitude\", \"Hour\"]\n",
    "label_indexers = {col: StringIndexer(inputCol=col, outputCol=f\"i_{col.replace(' ', '_').lower()}\").fit(data) for col in columns_to_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9657ed0-123e-4699-902a-06a5afb9f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block will transform data\n",
    "transformed_data = data\n",
    "for indexer in label_indexers.values():\n",
    "    transformed_data = indexer.transform(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ba12eb-b431-429f-850c-501235e55c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 will contain the indexed values only, which means they are all integer -> ready for training\n",
    "data2 = transformed_data.select(\"i_date\",\"i_iucr\",\"i_primary_type\",\"i_description\",\"i_location_description\",\\\n",
    "                    \"i_arrest\",\"i_year\",\"i_block\",\"i_domestic\",\"i_district\",\"i_ward\",\"i_fbi_code\",\"i_community_area\",\"i_latitude\",\"i_longitude\",\"i_hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5dac44-1276-49c7-a7b4-28886d3a4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\"i_date\",\"i_iucr\",\"i_primary_type\",\"i_description\",\"i_location_description\",\"i_year\",\"i_block\",\\\n",
    "                    \"i_domestic\",\"i_district\",\"i_ward\",\"i_fbi_code\",\"i_community_area\",\"i_latitude\",\"i_longitude\",\"i_arrest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20036de-f310-4d0f-a824-312284637a44",
   "metadata": {},
   "source": [
    "`Step 2: Create a vector-assembler to combine individual features into a vector in a new column, which called 'features_for_arrest'.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ea258b-0996-45cb-b64c-cb37f573b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=input_features, outputCol=\"features_for_arrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7a6941-9ac0-4bf4-8b9b-326d2378641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data = assembler.transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dffa69-ad6b-4a9b-b3f5-c0d02ab00e65",
   "metadata": {},
   "source": [
    "`Step 3: Use a StandardScaler to center the data - saved the centered data into a new column called \"scaled_features\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68c2483d-3fcc-48ec-81a1-94959aa48d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features_for_arrest\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(assembled_data)\n",
    "scaled_data = scaler_model.transform(assembled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb831c10-b1de-486f-b556-c6e3f2f609c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[i_date: double, i_iucr: double, i_primary_type: double, i_description: double, i_location_description: double, i_arrest: double, i_year: double, i_block: double, i_domestic: double, i_district: double, i_ward: double, i_fbi_code: double, i_community_area: double, i_latitude: double, i_longitude: double, i_hour: double, features_for_arrest: vector, scaled_features: vector]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c256e-344a-40f0-b4f9-ba25d3c8b0b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd85668-3ebf-4090-a5a5-1902b7d8c594",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36529c5-0b12-46b7-ac78-a936c406f02e",
   "metadata": {},
   "source": [
    "####  Train the model with the reduced data. I used RandomForestClassifier instead of PySpark DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1e1990-34b6-4958-9c17-005324407d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47467d08-5c84-49f4-a769-7333759f45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "# \"pcaFeatures\" is the hyperparameter that predicts arrest or not\n",
    "# \"i_arrest\" is our target variable\n",
    "pandas_df = scaled_data.select(\"scaled_features\", \"i_hour\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "442ed721-8354-4c78-9f75-b90084929112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PCA features and target variable\n",
    "X = pandas_df[\"scaled_features\"].tolist()\n",
    "y = pandas_df[\"i_hour\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4b1ac3-15fc-49ca-a163-2a35d44d753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852fcdc2-5d91-4e27-978c-2348139ec87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data again just in case\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8c9a14-6fee-4c25-b6cc-0404955bca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011d125-4290-4819-964f-1efa4eea3eb4",
   "metadata": {},
   "source": [
    "`Above is the model that predicts the value of Arrest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9a262f4-0442-42fe-b543-ba63fb24f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db3b00-74ad-486c-8524-fa1965c82c5b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba2333-c0df-4c68-a2dc-fe44ccf923c6",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9862539c-4c6c-4e36-b14f-65ce824ca723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.59%\n"
     ]
    }
   ],
   "source": [
    "# Use test_data to evaluate our model \n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd24f77-a831-4647-a7f4-c7b6a310fd82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
